## [데일리 스크럼]

**Stored Procedure ?**

일련의 쿼리를 마치 하나의 함수처럼 실행하기 위한 쿼리의 집합 

**SP의 장점**

1. DB 보안 향상 

- 자체 보안 설정 기능을 통해 단위 실행 권한 부여 가능

2. 기능 추상화

- 어떤 어플리케이션에서도 사용가능

3. 네트워크 트래픽 최소화

- 서버에 전달하는 코드 문자열 최소화

4. 절차적 기능 구현 

- if, while문 등과 같은 제어문 적용

5. 캡슐화의 이점

- SP 내의 로직을 변경하더라도 인터페이스의 변화가 없다면 사용자 어플리케이션에 영향이 없음

**SP의 단점**

1. 낮은 처리 성능 

- 문자, 숫자열 연산에 SP를 사용하면 느린 성능(이러라고 만든게 아님 ⇒ 최소화해라)
- 서버에서 처리하는게 유리함

2. 복잡한 비지니스 로직 개발의 어려움

- 구현할 수 있지만 어렵다 → 서버에서 수행하는 것을 추천

3. 디버그의 어려움 

4. 개발 유지의 어려움 

**SP의 생성날짜, 기능 등을 주석으로 설정해서 다는 것이 좋다.**

**예제로 알아보는 SP**

[[MSSQL] 저장 프로시저 문법 및 사용 예시](https://gameserverengineer-k.tistory.com/7)

> FE

> BE

빅데이터 분석 알고리즘 - 보고 우리가 사용할만한 알고리즘을 찾는 것이 오늘의 목표 

[빅데이터 분석 유형 및 알고리즘 맵](https://dbrang.tistory.com/1536)

현재 코로나 데이터 & 유동인구 데이터로 뽑아 낼 수 있는 그래프

1. 시간대별 유동인구 
2. 월별 유동인구
3. 구군별 유동인구 
4. 월별 코로나 걸린 환자수
5. 구군별 코로나 걸린 환자수 

2-4를 연결하여 2개를 동시에 그래프로 보여줄 수 있을 것

3-5를 연결하여 2개를 동시에 그래프로 보여줄 수 있을 것 

[Python - 2축 그래프 그리기](http://blog.naver.com/PostView.nhn?blogId=onlyjeje&logNo=221168953266)

코로나 - 유동인구 수가 비슷한 동향을 보인다면 낮은 지역을 추천해주는 간단한 상관관계 정도는 가능할 수도 

어떤 알고리즘을 뽑아야되는 지는 잘 모르겠음 

1. k-means를 활용해 유동인구수 & 코로나가 많은 지역과 적은 지역은 각각 군집화하여 시각화 

    [데이터 분석 초보자를 위한 k-means clustering (with Scikit-Learn)](https://velog.io/@gayeon/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D-%EC%B4%88%EB%B3%B4%EC%9E%90%EB%A5%BC-%EC%9C%84%ED%95%9C-k-means-clustering-with-sklearn)

2. 콜라보레이션 필터링을 통해 유동인구수와 코로나 데이터를 이용해 앞으로 코로나가 잘 발생할 것 같은 예측 지역과 그에 따른 유동인구수 예측 (정확도 고려안함)

    [이수진의 블로그](https://lsjsj92.tistory.com/568)

 

이후엔 회원 관리 & 토근 저장

[참고자료 - 이건 장고가 아니라 자바]

[[서버개발캠프] 인증 서버 - 로그인 : JWT + Redis](https://yunb2.tistory.com/6)

[이건 cache로 저장하는 방법]

[Django에서 SSO하기](https://nevercaution.github.io/django-sso/)

[여기엔 다 있는데 레디스에 토큰을 저장하는 법을 다음 포스팅에서 알려준댔는데 포스팅이 안올라옴]

[[smileGate] 2차 과제 (2) Auth 서버 구현](https://ssungkang.tistory.com/entry/smileGate-2%EC%B0%A8-%EA%B3%BC%EC%A0%9C-2-Auth-%EC%84%9C%EB%B2%84-%EA%B5%AC%ED%98%84)

데이터 관리 

[이건 우리 데이터가 크니까 필요한 데이터를 Redis 서버에 캐싱해서 관리하는 것도 괜찮을듯]

[Django에서 Redis를 이용해 Caching하기](https://jupiny.com/2018/02/27/caching-using-redis-on-django/)

[Django 16. Django & django-redis](https://velog.io/@jiffydev/Django-16.-Django-django-redis)

[Redis를 활용한 데이터 캐싱하기](https://nachwon.github.io/redis/)

1. 회원가입 - 회원 모델 , 이메일 인증 
    - 이메일, 패스워드(암호화), 인증여부

    [[Django] 이메일 인증](https://velog.io/@dongsagi90/Django-%EC%9D%B4%EB%A9%94%EC%9D%BC-%EC%9D%B8%EC%A6%9D)

2. 로그인, 로그아웃 - 토큰 발급 (레디스 서버에 저장)
3. 레디스 서버에 데이터 올리기(캐시 > DB) 
판다스로 그래프 표시(한 5개) 
k-means까지 짜기 
4. 추천 알고리즘 짜기 
5. https ⇒ 지도 api를 불러올 때 필요함 : 포트포워딩 할 것 

python [manage.py](http://manage.py) startapp user(사용할 기능)


### [데일리 스크럼]

[](https://www.grabbing.me/6166144602844aab9b361c79b8f90785)

### [오늘의 이슈]

[drf-yasg를 이용한 Swagger 문서 자동화](https://velog.io/@lu_at_log/drf-yasg-and-swagger)


### [데일리 스크럼]

Spring native Beta !

⇒ 최신 기술 동향을 파악할 것 ! (관심이 있는지를 파악)

[Announcing Spring Native Beta!](https://spring.io/blog/2021/03/11/announcing-spring-native-beta)

[추가]

해당 기사에 대한, 컨설턴트분 추가 의견 입니다. 본 글을 보고, 시니어 급의 개발자의 시야가 어떤지 참고하시면 좋을 것 같네요 

19년도에 자바 생명연장의 꿈 Quarkus 밋업에 갔었는데 그때 네이티브 지원하는 GraalVM을 사용하는 레드햇 오픈소스였는데 스프링에도 슬슬 이제 적용하는군요

# **그당시 공유했던 내용 재공유 합니다.**

Quarkus의 메이븐 플러그인을 사용해서 기존 자바 프로젝트를 오라클 GraalVM의 네이티브 컴파일러를 호출해서 실행가능한 네이티브 바이너리를 생성하는 데모도 진행했습니다.
컴파일은 많이 느리지만 맥에서 리눅스용 바이너리를 생성해서 리눅스 컨테이너에 올려 도커로 실행하니 엄청 빠르게 시작되더라구요 메모리도 적게먹는다 하고요
JAVA가 무거워서 람다에 적용하기 힘든 경우 방법이 하나 생기긴 한것 같습니다.
하지만 아직 GraalVM이 Stable 하지 않고 최적화가 너무 되기 때문에 동적인 클래스 로딩이나 리플렉션 관련해서는 에러가 나지 않을까 싶어 상용에 적용하기에는 좀 이르다는 느낌입니다.

사용법
[https://quarkus.io/guides/building-native-image-guide.html](https://quarkus.io/guides/building-native-image-guide.html)
설명
[http://www.opennaru.com/open-source/quarkus-performance/](http://www.opennaru.com/open-source/quarkus-performance/)


### [데일리 스크럼]

HA - 2부

**HA**(고가용성)

서버와 네트워크, 프로그램 등의 정보 시스템이 오랜 기간 동안 **지속적으로** 정상 운영이 가능한 성질 

= 시스템에서 이슈 발생 시, 얼마나 빠른 시간 내에 **복구**를 할 수 있는가?

**Active / Standby(=Backup) / Master / Slave**

**HA 방식**

- 클러스터링
각기 다른 서버들을 하나로 묶어서 하나의 시스템 같이 동작하게 함
- 로드밸런싱
부하 분산을 위해서 Virtual IP를 통해 여러 서버에 접속하도록 분배하는 기능 
로드 밸런싱 실패시 → **fail over**
    - 참고
- RAID
여러 개의 하드디스크에 일부 중복된 데이터를 나눠서 저장하는 기능



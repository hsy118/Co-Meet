> **공통**

주간 지라 설정(스프린트, 에픽, 스토리) 

발표 자료 준비

- **참고**

  [sqeunce diagram help website](https://app.diagrams.net/)

  [ERD Diagram help website](https://www.datensen.com/mongodb-schema-design/mongodb-schema-design.html)

  [icon website](https://www.flaticon.com/search?word=mask)
  
> **FE**

**랜딩 페이지** 

1. 네브바 + 배경 머지 - 월
2. 로그인 버튼 이벤트 추가 - 월
3. 회원가입 버튼 이벤트 추가 - 월
4. 에니메이션 구현 - 월

**장소 추천**

1. 장소 추천 와이어프레임 다듬기 - 화 or 수
2. 장소 추천 페이지 레이아웃 & 스타일링 - 화
3. 장소 추천 기능 구현 || 목업 데이터로 보여주기만- 목
- 브랜드 컬러 설정

> **BE**

- **현재 위치 api
→** 지도 api + 현재 위치를 통해 해야될 듯?
- **데이터 크롤링** (서울 데이터 MongoDB 설정) 
→ 데이터는 불러왔는데 저장을 어캐해야할까요,, ⇒ djongo 공식 홈페이지를 참고해봅시다!
- **mm과 Django 연동 설정**(터미널창 로그 연결) 
→ 비밀번호 & token 이슈 질문
- **데이터 저장** (csv 파일)

    → 사용할 데이터 : 카드 사용량, 유동인구 

**Main Function 정리 및 개발 시작** 

1. 유동인구 컬럼 기반 낮은 구역 뽑기 

2. 카드샤용량 컬럼 기반 낮은 구역 뽑기 

3. 유동인구 & 카드사용량 퍼센트 기반 낮은 구역 뽑기 

4. 입력 위치 기반 낮은 구역 뽑기 

5. 현재 위치 기반 낮은 구역 뽑기

**21.03.16**

새로운 내용 
행정동과 법정동이 엄연히 다른 개념을 가지고 있다 => 처리 방식을 고민해야된다.

주소를 서버에서 받는다. → 

코로나 데이터 / 유동인구 / 카드 사용량 데이터 기반으로 안전한 지역 도출 

- 회원가입, 로그인 → 회원관리
- 코로나 현황 시각화
- 주소를 받고 처리 → main

    1. 코로나 데이터로 안전한 구를 뽑아내는 것이 1순위 

    - → 서울 전체 리스트
    - 일정한 기준이 필요할 듯 일정 기간(한 달/한 주/2주) 내에 해당 구에서 몇 번 코로나 이슈가 있었는 지? 데이터를 도출해내고 그 데이터로 안전한 구를 뽑아내보자.
    - 유동인구

    2. 유동인구  기반으로 그 구가 안전한지 재 검색

    3. 그렇지 않다면 다음 구로 이동 

- Mattermost 연동 → log 처리 (질문) 봇, personal access token을 받을 수 있는 지


- **참고**

    내가 본 크롤링 데이터 하는 법(pip install 관련해 있음)

    [Google Colaboratory](https://colab.research.google.com/github/corazzon/cracking-the-pandas-cheat-sheet/blob/master/seoul-covid-19-00-scraping-data.ipynb#scrollTo=PiqrecOZo4Kb)

    지금 내가 보고 있는 장고로 데이터 뽑기

    [Django로 크롤링한 데이터 저장하기](https://beomi.github.io/gb-crawling/posts/2017-03-01-HowToMakeWebCrawler-Save-with-Django.html)

    현재 위치 

    [(HTML&DOM) Geolocation API(GPS) - 위치 정보 가져오기](https://www.zerocho.com/category/HTML&DOM/post/59155228a22a5d001827ea5d)
    
    주소 검색
    
    [카카오 우편번호 서비스 API](https://postcode.map.daum.net/guide)
    
> 데일리 스크럼

**21.03.16**


## [HA 관련 - Active, Standby, Mastter, Slave, Backup]

- Active : 평상시 Request 를 받아 처리할 수 running 중의 시스템
- Standby ( = Passive = Backup ) : Active 시스템의 장애시 Request 를 처리할 수 있는 시스템
- Master : Write 를 처리할 수 있는 Active 시스템
- Slave : Read 를 처리할 수 있는 Active 시스템


**21.03.18**

## Fiddler

**피들러 Fiddler** 는 HTTP와 HTTPS의 프로토콜을 캡처하고 분석할 수 있는 **웹디버깅 툴**이다.

클라이언트에서 서버로 요청한 내역과 결과의 모든 데이터를 확인할 수 있으며, 주로 트래픽 조작, 기능확장, 분석, 모니터링 등에 유용하게 쓰인다.

[피들러 Fiddler : 설치 및 사용법](https://pyoungt.tistory.com/35)

[피들러 Fiddler: 참고 사이트](https://www.telerik.com/fiddler)

**21.03.19**

## 평가 방식

평가 ⇒ 최고 평점은 항목 당 1명만 !! (지키지 않을 시 평가자에게 불이익)

1일 1커밋 ⇒ 금요일 발표날은 꼭 커밋할 것 (놓치는 사람이 많음)

라이브 방송 ⇒ 9시 기준 로그를 통해 확인하니 그전에 꼭 들어올 것